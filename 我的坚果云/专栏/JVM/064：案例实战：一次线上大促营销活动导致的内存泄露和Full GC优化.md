### 1、线上故障场景

大促活动开始之后，直接导致线上一个系统的CPU使用率飙升，而且因为CPU使用率太高，导致系统几乎陷入卡死的状态，无法处理任何请求！

在重启系统之后，会好一段时间，但是很快又立马发现机器的CPU使用率飙升，继续导致系统卡死。



### 2、初步排查CPU负责过高的原因

这里给大家说一下线上系统的机器CPU负责过高的两个常见的场景。

1. 第一个场景，是你自己在系统里创建了大量的线程，这些线程同时并发运行，而且工作负责都很重，过多的线程同时并发运行就会导致你的机器CPU负责过高。
2. 第二个场景，就是你的机器上运行的JVM在执行频繁的Full GC，Full GC是非常耗费CPU资源的，他是一个非常重负载的过程。

所以一旦你的JVM有频繁的Full GC，带来的一个明显的感觉，一个是系统可能时不时会卡死，因此Full GC会带来一定的"Stop the World"问题，一个是机器的CPU负载很高。

大家完全可以用排除法来做。首先看一下JVM Full GC的频率，通过jstat也好，或者是监控平台也好，很容易看到现在Full GC的频率。

### 3、初步排查频繁Full GC的问题

大家通过之前大量的案例和文章已经初步可以得到结论，如果有频繁Full GC的问题，一般可能性有三个：

- 内存分配不合理，导致对象频繁进入老年代，进而引发频繁的Full GC；
- 存在内存泄露等问题，就是内存里驻留了大量的对象塞满了老年代，导致稍微有一些对象进入老年代就会引发Full GC；
- 永久代里的类太多，触发了Full GC。

当然还有之前案例说过，如果上述三个原因都不存在，但是还是有频繁的Full GC，也就是工程师错误的执行"System.gc()"导致的。但是这个一般很少见，而且之前讲过，JVM参数中可以禁止这种显式触发的GC。

之前我们介绍过jmap+jhat的组合来分析内存里的大对象，今天我们介绍另外一个常用的强有力的工具，MAT。

### 4、对线上系统导出一份内存快照

先用jmap命令导出一份线上系统的内存快照即可：

```bash
jmap -dump:format=b,file=文件名[服务进程ID]
```

拿到内存快照之后，其实就是一份文件，接着就可以用jhat、MAT之类的工具来分析内存了。

### 6、基于MAT来进行内存泄露分析

使用MAT打开一个内存快照之后，点"Leak Suspects"按钮，就是内存泄露分析。

让开发工程师去排查系统的代码问题，为什么会创建这么多对象，而且始终回收不掉？

这是**"典型的内存泄露"**，即系统创建了大量的对象占用了内存，其实很对对象是不需要使用的，而且无法回收掉。

后来找到了一个原因，是在系统里做了一个JVM本地的缓存，把很多数据都加载到内存里去缓存起来，然后提供查询服务直接从内存走。

但是因为没有限制本地内存的大小，并且没有使用LRU之类的算法定期淘汰一些缓存里的数据，导致缓存在内存里的对象越来越多，进而造成了内存泄露。

解决问题很简单，只需要使用类似EHCache之类的缓存框架就可以了。它会固定最多缓存多少个对象，定期淘汰一些不怎么访问的缓存，以便于新的数据可以进入缓存中。