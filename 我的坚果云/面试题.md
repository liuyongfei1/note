### StringBuilder和StringBuffer区别

#### 区别一：线程安全

StringBuffer：线程安全，因为StringBuffer的所有公开方法都是synchronized修饰的，而StringBuilder并没有synchronized修饰。

#### 区别二：缓存区

StringBuilder代码段：

```java
@Override
public String toString() {
  // Create a copy,don't share the array
  return new String(value,0,count);
}
```

StringBuffer代码段：

```java
private transient char[] toStringCache;
 
@Override
    public synchronized String toString() {
        if (toStringCache == null) {
            toStringCache = Arrays.copyOfRange(value, 0, count);
        }
        return new String(toStringCache, true);
    }
```

可以看出，StringBuffer每次获取toString都会直接使用缓存区的toStringCache值来构造一个字符串。

而StringBuilder则每次都需要复制一个字符串，再构造一个字符串。

#### 区别三：性能

既然StringBuffer是线程安全的，他的所有公开方法都是同步的，StringBuilder是没有对方法加锁同步的，所以StringBuilder的性能要远大于StringBuffer。

#### 总结

StringBuffer是线程安全的，适用于在多线程操作；单线程场合则StringBuilder更适合。



### 开发一个提供给别人使用的SDK?

### Restful的 PUT与POST区别？

例如，eshop项目里，ScheduleApi 里的那些请求为什么都用PUT接收？

PUT和POST都可以创建和修改资源，它们的区别是什么？

- 在更新资源时，PUT和POST基本相同；
- 在创建资源时，PUT可以指定资源路径，POST无法指定资源路径。

比如：

/user/create，每次调用它都会新建一个用户，这时可以用POST；

/user/update/{id}，PUT方法更加关心一个具体资源对应的URI，比如更新当前用户信息，这里可以用PUT。

当以更新的形式来修改某一具体资源时，如何判断用PUT还是POST呢？

很简单，如果该更新对应的URI多次调用的结果一致，则PUT:

比如：更新用户信息接口，/user/update/{id}，每次更新提交相同内容时，结果都一致，则用PUT；

每次更新提交相同内容最终的结果不一致时，则用POST。

举个常见的例子，一个接口的功能是将当前余额减一个值，每次提交该值为100，接口如下：

/amount/deduction，调用一次，你的余额-100，调用两次，余额-200，这个时候就用POST。



### ORM

#### 什么是ORM

对象关系映射。

Object：就是 javaBean；

Relational：关系，二维表，数据库中的表；

Mapping：映射，对象中的属性 与表中的字段存在对应关系。

#### 主流的ORM框架

- JPA：Java Persistence API，JPA通过JDK 5.0注解或XML描述对象－关系表的映射关系（只有接口规范）；
- Hibernate： 最流行额ORM框架，通过对象-关系映射配置，可以完全脱离底层SQL;
- Mybatis：apache的一个开源项目iBatis，支持SQL查询，存储过程和高级映射的优秀持久层框架；
- Apache DBUtils，Spring JDBCTemplate。

##### Hibernate编写流程概要

1. 创建数据库和表；
2. 导入hibernate的jar包；
3. 编写核心配置文件hibernate.cfg.xml，配置获得数据源链接、隐射文件等参数；
4. 编写映射文件 hibernate mapping （*.hbm.xml）;
5. 使用api测试。

详见：https://blog.csdn.net/uotail/article/details/81813210



#### k8s

一句话说：就是管理docker容器的一个玩意。

具体的说：能把n个docker容器组装到一起，打包弄成一个整体俗称pod，然后可以在各个物理节点上创建这个pod。

其实对于这个pod，k8s可以进行弹性伸缩，只需简单配制一下就能创建n个一摸一样的pod；也可以对这n个pod进行负载均衡，也可以对这n个pod的运行资源进行限制比如每个pod限制几个cpu多少的内存等等。

#### 线上CPU 100%后，怎么解决

找到是哪个进程后，再找出这个进程里边占用最高的那个线程，拿出进程之后就转换为16进制的一个，然后再用jstack，打出它具体的堆栈，定位到具体的哪一行代码

1、找出占用CPU最高的进程

执行top -c，按P，按照 CPU占用率排序：

<img src="面试题.assets/image-20220329201407801.png" alt="image-20220329201407801" style="zoom:50%;" />



2、找出这个进程占用CPU最高的线程

top -Hp 30120

这个显示的pid是十进制的，需要转化为 十六进制。

3、导出进程快照

jstack -l 3033 > ./3033.stack

4、执行grep命令，看那个线程做了什么

```bash
cat 3033.stack |grep 'bda' -C 8
```

从而定位到问题。

详细参考：https://www.cnblogs.com/xichji/p/11713300.html



Mysql

Redis的集群

Dubbo的调用链路

常用的设计模式

分布式锁

Spring Cloud、 bus

---------------

需要充电的：

1. java乐观锁和悲观锁的区别

2. synchronized 偏向锁 轻量级锁

    

### Java线程的几种状态

https://blog.csdn.net/xyzyhs/article/details/121417200

- NEW-新建
- RUNNABLE-可运行
- BLOCKED-阻塞
- WAITING-等待
- TIMED_WAITING 等待（有时限）
- TERMINATED-终结

![Java线程状态](面试题.assets/Java线程状态-0013421.png)

### 并发编程系列——wait原理的讨论

https://blog.csdn.net/java_lyvee/article/details/110996764?spm=1001.2014.3001.5501

**synchronized**关键字是倒序唤醒，但是如果你使用**ReentrantLock**那么则是正序唤醒；

状态：没有看。

### redis的线程模型

redis 内部使用文件事件处理器 file event handler。这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。



文件事件分派器从队列中获取socket，交给连接应答处理器。

**连接应答处理器**会创建一个与客户端能够通信的socket01，并将该 socket01 的 AE_READABLE 事件与**命令请求处理器**关联。

假设此时客户端发送了一个 set key value 请求，

redis6.0之后的版本抛弃了单线程模型的这一设计，原本使用单线程运行的redis也开始选择性的使用多线程模型。

redis的多线程只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。

### redis的主要数据类型

- String
- Hashes
- Set：无序集合，自动去重。
- Lists
- Sorted Sets

### Redis过期策略

#### 定期删除

#### 惰性删除

#### 内存淘汰机制

allkeys-lru：

当内存不足以容纳新写入的数据时，在键空间中，移除最近最少使用的key（这个是最常用的）。

### Redis如何才能做到高可用

Redis的高可用架构，叫做 failover 故障转移，也可以叫做主备切换。

master node 在故障时，自动检测，并将某个 slave node 自动切换为 master node 的过程，叫做主备切换。这个过程，实现了redis的主从架构下的高可用。

### Redis哨兵集群实现高可用

- 集群监控
- 消息通知
- 故障转移
- 配置中心

### 哨兵的核心知识

- 哨兵至少需要3个实例，来保证自己的健壮性；
- 哨兵+Redis主从的部署架构，是不保证数据零丢失的，只能保证redis集群的高可用性。

### Redis哨兵主备切换的数据丢失问题

- 异步复制导致的数据丢失；
- 脑裂导致的数据丢失

#### 数据丢失问题的解决方案

```bash
min-slave-to-write 1
min-slave-max-tag 10
```

表示，要求至少有1个slave，数据复制和同步的延迟不能超过10秒。

如果说一旦所有的slave，数据复制和同步都超过了10秒，那么这个时候，master就不会再接收任何请求了。

### Redis的持久化有哪几种方式？

#### RDB

#### AOF

#### RDB和AOF到底该如何选择

### 缓存雪崩

缓存雪崩的事前事中事后的解决方案如下：

- 事前：Redis高可用，主从+哨兵，避免全崩溃；
- 事中：本地cache缓存+ hystrix限流&降级，避免mysql被打死；
- 事后：redis持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。

### 缓存穿透

假设一秒5000个请求，结果其中4000个请求都是黑客发出的恶意攻击。

黑客发出的那4000个攻击，缓存中查不到，每次你去数据库中里查，也查不到。

解决方式很简单：每次系统A只要从数据中没查到，就写一个空值到缓存里去，比如： set -999 UNKNOW。

然后设置一个过期时间，这样下次有相同的key来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。

### 缓存击穿

就是说某个key非常热点，访问非常频繁，处于集中式高并发访问的情况，当然这个key在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库。

不同场景下的解决方式：

- 若缓存的数据基本不会发生更新的，则可尝试将该热点数据设置为永不过期；

- 若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于Redis、zookeeper等分布式中间件的分布式互斥锁，或者本地互斥锁，以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新内存。

- 若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。

  

### JVM

#### JVM有哪些垃圾回收算法

https://apppukyptrl1086.pc.xiaoe-tech.com/detail/i_5d11dd43d099f_U4Z2ECuX/1?from=p_5d0ef9900e896_MyDfcJi8&type=6&parent_pro_id=

新生代垃圾回收算法：复制算法
   1.两块内存区域，然后对正在使用的那块内存区域将垃圾对象标记出来（Yong GC 会采用复制算法，从GC Roots（方法的局部变量、类的静态变量）开始追踪，标记出来存活的对象）
   2.然后将存活的对象转移到另一块内存区域中，紧凑的排列在一起，保证没有内存碎片。
   3.但是这样经常有一半的内存区域利用不上，所以就对这个算法进行了优化。
 优化后的：
   1.把Eden区的存活对象都一次性转移到空着的Survivor区里；
   2.接着Eden区就会被清空，然后再次分配新对象到Eden区。

   什么情况下新生代里的对象会进入老年代

老年代垃圾回收算法：标记整理算法
   1.首先标记出来老年代当前存活的对象，这些对象可能是东一个西一个
   2.接着会让这些存活对象在内存里进行移动，把存活的对象都挪到一起，避免垃圾回收过后出现过多的内存碎片；
   3.再一次性的把垃圾对象都回收掉。
大家要注意一点，这个老年代的垃圾回收算法的速度至少比新生代的垃圾回收算法的速度要慢10倍。

#### 进入老年代的几个条件

1、年轻代躲过15次；

2、建的大对象超过了JVM设置的参数值；

3、一次YongGC过后，存活的对象太多了，导致Survivor区域放不下了；

4、可能几次Yong GC过后，Survivor区域中的对象占用超过了50%的内存，此时会判断年龄1+年龄2+年龄n对象的总和超过了Survivor区域的50%，此时年龄N及年龄N以上的对象都进入老年代，这就是动态年龄判定规则。

#### 触发老年代的几个条件

1、老年代自身有一个阈值，有一个JVM参数可以控制，一旦老年代内存使用达到这个阈值，就会触发Full GC，一般建议调大一点，比如92%；

2、在执行Yong GC 之前，如果判断发现老年代可用空间小于了历次Yong gc过后存入老年的平均对象大小的话，那么就会在Yong GC之前触发Full GC，先回收掉一批老年代对象，然后再执行Yong GC；

3、如果Yong gc过后存活的对象太多，survivor区域也放不下，就要进入老年代，此时老年代也放不下，就会触发Full GC，回收掉老年代一些对象，再把这些存活的对象放入老年代中。

#### JVM年轻代垃圾回收器ParNew

1. 新生代垃圾回收器ParNew采用`多线程垃圾回收机制`，可以充分利用线上机器多个CPU的优势。

2. ParNew在合适的时机执行Yong GC的时候，会把系统程序的工作线程全部停掉，禁止程序继续运行创建新的对象；
3. 然后自己就用多个垃圾回收线程去进行垃圾回收，回收的机制和算法就是上面总结的复制算法。
4. 可以通过使用"-XX:+UseParNewGC"选项，JVM启动之后对新生代进行垃圾回收的，就是ParNew垃圾回收器了。

#### JVM老年代垃圾回收器CMS

采用的是标记清理算法。其实非常简单，就是之前文章里讲过的标记方法区标记出那些对象是垃圾，然后把这些垃圾对象清理掉。

##### 如果Stop the World然后垃圾回收会如何？

如果停止一切工作线程，然后慢慢的去执行"标记-清理"算法，会导致系统卡死时间过长，很多响应无法处理。

所以CMS垃圾回收器采用的是`垃圾回收线程和系统工作线程尽量同时执行的模式来处理的`。

##### CMS如何实现系统一边工作的同时进行垃圾回收

CMS在执行一次垃圾回收的过程一共分为4个阶段：

1. 初始标记；=》系统的工作线程会全部停止，
2. 并发标记；=》这个阶段会让系统线程可以随意创建各种新对象，继续运行（这个阶段就是对所以老年代对象进行GC Roots 追踪，其实是最耗时的）
3. 重新标记；=》系统的工作线程会停止下来。这个阶段需要会第2阶段生成的存活对象和重新变为的垃圾对象进行标记；
4. 并发清理。=》系统会继续运行。=》这个阶段也很耗时，因为要对对象进行清理，但是他也是跟系统程序并发运行的，所以其实也不影响系统的执行。

所以大家看完CMS的垃圾回收机制之后，就会发现，他已经尽可能的进行了性能优化。

最耗时的第二阶段和第四阶段，其实是要对老年代对象进行GC Roots追踪，然后就是对各种垃圾对象从内存里清理掉，这是很耗时的，但是都是和程序并发运行的，所以这两个最耗时的二阶段对性能影响不大；

只有第一个和第三个阶段是需要"Stop the World"的，但是这两个阶段，都是简单的标记而已，速度非常的快，所以基本上对系统运行影响也不大。

#### Jstat、jmap、MAT

##### jstat

```
jstat -gc 140

jstat -gc 140 1000 10
```

##### jmap

```
jmap -heap 140   =》 效果跟 jstat -gc 140 差不多，还没有jstat的全

jmap -histo 140 | more   => 查看系统运行时的对象分布

jmap -dump:live,format=b,file=dump.hprof 140 =>生成堆内存快照
```

这个堆内存快照是个二进制文件，不能直接打开。它把这一刻堆内存里所有的对象的快照放到文件里去了，供你后续分析。

##### MAT

memory analyzer tool，是一种快速的，功能丰富的 Java 堆内存分析工具。能帮你找到内存泄露和减少内存消耗。

有一个 Dominator Tree 功能，以占用总内存百分比的形式列举出了所有的实例对象，可以用来发现大内存对象。



### redis支持的数据结构

1、String
2、Hash
   hset person name zhangsan
   hset person age 30
   hset person id 12
   hget person name
3、List 有序,可以重复
   lpush mylist 1
   lpush mylist 2
   lpush mylist 3
   lpush mylist 3
   lrange 0 -1  => 0 是开始位置，-1是结束位置，即查看所有
4、Set 无序，自动去重
   sadd myset 1
   sadd myset 2
   sadd myset 3
   smembers myset => 查看全部元素
   sadd myset 1 => 返回0，执行添加失败（即自动去重）
5、Sorted Sets 排序的set，去重，可以排序
   zadd board 85 a
   zadd board 70 b
   zadd board 60 c
   zadd board 90 d
   zrevrange board 0 2 => 获取排名前3的用户 

#### Redis持久化

redis-server/redis-cli   **5.0.8 版本**

- RDB：RDB持久化机制，是对Redis中的数据执行周期性的持久化；
- AOF：AOF机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在Redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集。

`redis从4.0开始，就默认提供了混合持久化的机制（同时使用 RDB + AOF）`。

混合持久化的数据恢复和AOF持久化过程是一样的，只需要把 appendonly.aof 文件放到redis的根目录下，在redis启动时，只要开启了AOF持久化，redis就会自动加载并恢复数据。

那么在 Redis重启的时候，会使用 AOF来重新构建数据，因为AOF中的数据更加完整。

##### RDB优缺点

- RDB 会生成多个数据文件，每个文件代表了某一时刻 redis 中的数据，这种多个数据文件的方式，非常适合做冷备；（这里的冷备可以理解为将已生成的文件拷贝到其他机器或者云服务器上。）
- RDB 对 Redis对外提供的读写服务影响非常小，可以让Redis保持高性能。因为Redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可；
- 相对于AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis进程，更加快速；
- 如果想要在Redis故障时，尽可能减少丢失数据，那么RDB 没 AOF 好。一般来说，RDB数据快照文件，都是每隔5分钟或者更长时间生成一次，这个时候一旦redis进程宕机，那么会丢失最近5分钟的数据。
- RDB每次在fork子进程来执行RDB数据快照的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，甚至数秒。

##### AOF优缺点

- AOF 可以更好的保护数据不丢失，一般AOF会每隔1秒钟，通过一个后台线程执行 fsync 操作，最多丢失1秒的数据；
- AOF 是以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高；
- AOF有一个 rewrite 机制，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用fulshall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝AOF文件，将最后一条 flushall 命令给删了，然后再将AOF文件放回去，就可以通过恢复机制，自动恢复所有数据。
- AOF这种较为复杂的基于命令日志/merge的方式，比基于RDB每次持久化一份完整的数据快照文件的方式，更加脆弱一些。rewrite 过程有可能会导致 bug。因此每次rewrite的时候，并不是基于旧的指令日志进行merge，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。

##### RDB和AOF到底该如何选择

- 不要仅仅使用RDB，那样会丢失很多数据；
- 也不要仅仅使用AOF，有两个原因：第一通过AOF做冷备，没有RDB做冷备的恢复速度快；第二RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug；
- Redis支持同时开启两种持久化的方式。我们可以综合使用这两种持久化机制。使用AOF来保证数据不丢失，做为数据恢复的第一选择；用RDB做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复。

##### 结合我们公司的线上环境使用情况

运维把 RDB 和 AOF 给关了，说 RDB 在数据量较大的时候，容易造成 IO 堵塞。

我们使用 哨兵模式。哨兵集群（3个节点） + redis 主从（1主2从）的部署架构。

当master节点发生故障后，故障转移，slave 会自动切换为 master。

##### 在主备切换的时候的数据丢失问题

- 异步复制导致的数据丢失
- 脑裂导致的数据丢失

解决方案：

进行如下配置：

```bash
min-slaves-to-write 1
min-slaves-max-lag 10
```

表示要求，至少有1个 slave 能写，数据复制和同步的 延迟不能超过10秒，超过10秒的话，就直接拒绝客户端的写请求。



### 充电

1. 为什么要用jwt？
2. 分布式定时任务框架？Quartz，XXXJob？
3. 二分查找；
4. 树
5. Elasticsearch