元数据管理

数据字典/数据资产目录

数据质量监控/数据治理



### Atlas架构原理

<img src="1.assets/image-20220523190233709.png" alt="image-20220523190233709" style="zoom:50%;" />

Solr 是给用户提供的查询元数据的一个查询引擎，类似ES。

### Atlas使用

atlas在安装之初，需要手动执行一次元数据的全量导入，后续altas便会利用HiveHook 增量同步Hive的元数据。

### Hive元数据初次导入

进入到altas的安装目录下，cd hook-bin，会有一个 import-hive.sh。

直接执行：

```bash
sh  import-hive.sh
```

就会进行元数据的初次导入。

执行完毕后，刷新altas的 ui 界面。

### Hive元数据增量同步

增量同步的，无需人为干预，只要 hive 中的元数据发生变化（执行DDL语句），HiveHook 就会将元数据的变动通知 Altas。

除此之外，altas 还会根据 DML 语句获取数据之间的血缘关系。

### 血缘关系

还是在 atlas 的ui界面上，点击某个表之后，点击 Lineage 标签页，可以查看血缘关系。

比如这样的一个需求：

根据订单事实表和地区维度表，求出每个省份的订单次数和订单金额。

大概的sql语句：

<img src="1.assets/image-20220523221657873.png" alt="image-20220523221657873" style="zoom:50%;" />

关联：

<img src="1.assets/image-20220523221459494.png" alt="image-20220523221459494" style="zoom:50%;" />

查看ads_order_by_province 表的血缘关系：

<img src="1.assets/image-20220523222232162.png" alt="image-20220523222232162" style="zoom:50%;" />

还可以支持字段级的血缘查看：

比如我现在要看这个表下面的order_amount字段是怎么算的：

<img src="1.assets/image-20220523222629633.png" alt="image-20220523222629633" style="zoom:50%;" />

<img src="1.assets/image-20220523222710412.png" alt="image-20220523222710412" style="zoom:50%;" />

### Altas的内存配置

如果计划存储万个元数据对象，建议调整参数值获得最佳的 JVM GC 性能。详细可见：

https://www.bilibili.com/video/BV1jA411F76d?p=19&spm_id_from=pageDriver

<img src="1.assets/image-20220523223129623.png" alt="image-20220523223129623" style="zoom:50%;" />



--------------------------------------------------------------------------------------

不是尚硅谷的。

### 超全的大数据治理体系 数据如何治理

https://www.bilibili.com/video/BV1tf4y167Dz?spm_id_from=333.337.search-card.all.click

<img src="1.assets/image-20220523225153961.png" alt="image-20220523225153961" style="zoom:50%;" />

<img src="1.assets/image-20220523224555133.png" alt="image-20220523224555133" style="zoom:50%;" />

<img src="1.assets/image-20220523225301733.png" alt="image-20220523225301733" style="zoom:50%;" />

# 大数据治理体系全流程基础讲解

https://www.bilibili.com/video/BV1mF41177yK?spm_id_from=333.337.search-card.all.click

理论篇。

### 数仓基础之数据架构

<img src="1.assets/image-20220524161242920.png" alt="image-20220524161242920" style="zoom:50%;" />

### 数据治理之数据接入

- 数据探查
- 数据定义
- 数据获取
- 数据对账



####  数据对账实现方式

<img src="1.assets/image-20220524165934543.png" alt="image-20220524165934543" style="zoom:50%;" />

### 数据治理之数据处理

- 数据提取；
  - <img src="1.assets/image-20220524191752923.png" alt="image-20220524191752923" style="zoom:50%;" />
  - <img src="1.assets/image-20220524191857693.png" alt="image-20220524191857693" style="zoom:50%;" />
- 数据清洗；
  - <img src="1.assets/image-20220524192113838.png" alt="image-20220524192113838" style="zoom:50%;" />
  - <img src="1.assets/image-20220524192206903.png" alt="image-20220524192206903" style="zoom:50%;" />
  - <img src="1.assets/image-20220524192229139.png" alt="image-20220524192229139" style="zoom:50%;" />
  - <img src="1.assets/image-20220524192314273.png" alt="image-20220524192314273" style="zoom:50%;" />
- 数据关联
  - <img src="1.assets/image-20220524192433637.png" alt="image-20220524192433637" style="zoom:50%;" />

### 数据治理之数据质量、运维监控

<img src="1.assets/image-20220524192546691.png" alt="image-20220524192546691" style="zoom:50%;" />

其中第三部分，第四部分 政务中多用。

- 质量管理

<img src="1.assets/image-20220524192626402.png" alt="image-20220524192626402" style="zoom:50%;" />

<img src="1.assets/image-20220524192736563.png" alt="image-20220524192736563" style="zoom:50%;" />

<img src="1.assets/image-20220524192853092.png" alt="image-20220524192853092" style="zoom:50%;" />

- 运维管理

  这一块是大数据运维工程师来做的。

  - <img src="1.assets/image-20220524192932534.png" alt="image-20220524192932534" style="zoom:50%;" />
  - <img src="1.assets/image-20220524192947085.png" alt="image-20220524192947085" style="zoom:50%;" />
  - <img src="1.assets/image-20220524193109134.png" alt="image-20220524193109134" style="zoom:50%;" />

- 资源编目
  
- 分级分类

需要把我们处理完的数据，做成一个目录，然后做成可视化。

### 数据治理之数据组织

这一块就是偏向应用了。

- 第一部分：主题层

  - <img src="1.assets/image-20220524193539941.png" alt="image-20220524193539941" style="zoom:50%;" />
  - <img src="1.assets/image-20220524193712454.png" alt="image-20220524193712454" style="zoom:50%;" />

- 第二部分：专题层

  从主题层直接拿数据出来，可以作为应用的。
  - <img src="1.assets/image-20220524193847841.png" alt="image-20220524193847841" style="zoom:50%;" />
  - <img src="1.assets/image-20220524193920238.png" alt="image-20220524193920238" style="zoom:50%;" />
  - <img src="1.assets/image-20220524193947127.png" alt="image-20220524193947127" style="zoom:50%;" />

------------------------------------------------------------------

# 企业数据治理系列（一）数据资产管理实践白皮书4.0

https://www.bilibili.com/video/BV1Mb4y1f7E7/?spm_id_from=333.788.recommend_more_video.2

由中国通信院和大数据技术标准推进委员会，在2019年颁布的 《数据资产管理白皮书4.0版》。

以下这8个方面就是围绕着这个白皮书的内容展开的。

可以了解一下。

## 来看一下很多企业在做数据治理的时候遇到的问题：

### 问题1：缺乏统一的数据视图；

=》数据分散在各个业务系统里，特别是伴随着微服务架构的兴起，这样分散的局面会更加严重，从而导致业务人员无法感知数据的分布和更新的情况，也比较难收集到和汇总到有价值的数据。

### 问题2：数据质量低下

原始数据的缺失，统计口径的差异，都会导致脏乱差的数据无处不在，而质量低下的数据，会导致业务决策的偏差，这会导致 Rubbish In，Rubbish Out 的恶性循环。

### 问题3：缺乏数据价值的管理体系

哪些是你的核心客户，哪些是有高转化率的客户，哪些是你快要流式的客户，这些都需要做好精细化的客户标签管理，那这就会要求企业建立好自己一套核心价值数据的管理体系。

那么到底怎么去解决这些问题呢？数据资产管理白皮书，就提供了这样的一个方法论，它涵盖了如下：

<img src="1.assets/image-20220524221120019.png" alt="image-20220524221120019" style="zoom:50%;" />



## 一.数据标准

保障数据一致性和准确性的规范性约束。一般包括了基础指标和计算指标这么两个部分。

基础指标，比如性别，定义好一个统一的标准：男 =》0，女 =》1 类似这些；

计算指标，比如订单复购率呀，这些，定义好统一的标准，分子分母分别是谁，是否要排除一些异常的账号、异常的订单，是按下单时间，还是按付款时间来算，这些都需要在一个企业中达成一个统一的共识。

`那具体怎么体现在我们的业务系统中呢？=》它其实就可以是一个类似的wiki系统，只要把我们使用的数据标准，分门别类的罗列好，方便检索、查阅，在定义数据结构和值域的时候引用就可以了。`

## 二.数据模型

现实世界数据特征的抽象，用于表示一组数据和概念的定义。=》说人话，就是数据的数据结构。

数据结构ER图，版本化管理结构，类型、值域。

比如说你数据结构ER图，是用来描述各种业务主体的结构和它们之间的关系；比如说在电商领域下，我们往往会有用户、商品这样的数据结构。

`那数据模型在我们数据治理中体现在什么地方呢？=》它落地就体现在你数据库的结构中，但是我们既然谈治理，我们还是希望以文档的方式，版本化的来管理你的结构，从而方便管理、对比和追溯。`

## 三.元数据

"描述数据"的数据。

非常核心的作用就是 追溯数据的生成过程，并且做数据的血缘分析，那这对于评估数据变更造成的影响，或者说做全链路的数据，正确性核查这一方面的话，是有着非常重要的作用。

## 四.主数据

描绘企业核心实体的数据。

也可能是你企业的多条业务线，多个流程阶段所重复、共享的高价值数据。比如电商平台中，你商品的sku数据，订单数据和你用户的数据，供应商的数据，这些都是你最核心的主数据，也是你数据资产的核心内容。

`需要你识别他们的来源，做汇总，做清理，去建设这样一个主数据，从维护你数据的核心价值。`



## 五.数据质量

分为 完整性、规范性、一致性、准确性、时效性。

在实际数据生产的场景下，成本-效率-质量 永远是要被平衡的三角。
也就是说在你成本不变的情况下，提升质量，必然会降低效率；或者说在效率不变的情况下，提升质量，必然会增加成本，需要投入更多的人去做质量和核查和修正。

围绕质量的优化，包括快速的定位，快速的修复，最终都会兑现在你成本和效率提升的方面。

## 六.数据安全

涵盖的范围比较广。

- 比如从制度方面，你可以按照国家组织的相关法规，来评价你数据的安全风险，从而制定相应的安全制度和策略；
- 从技术层面来讲的话，需要保证你的数据再采集、传输、存储方面的安全性。比如说在传输的过程中，使用ssl协议加密，或者在数据存储的过程中，使用相应的数据控制策略等待；
- 在应用层面讲，我们需要对访问的数据加以控制，比如基于RBAC的访问控制模型，资源只能被拥有某个权限的角色对应的用户才能访问。

那整个安全方面来讲的话，希望通过制度、流程、手段、工具、产品的方式、做到"事前可管"、"事中可控"、"事后可查"。

## 七.价值

成本、应用价值。

价值可以围绕成本、应用价值两个方面来展开。

比如成本包含采集、传输、运维等方面的成功；

价值方面来讲的话可以通过他使用的分类、频次、对象和产生的收益效果来做评估。

举个例子，比如淘宝内部的应用服务器集群，每天会产生上面G，乃至上T的日志文件，那这会消耗大量的存储、计算成本，包括检索日志，存储日志等各个环节。

那相对而言，另外一部分数据可能会更有价值，就是说基于海量的日志所统计、检索出了一些不同地域搜索关键词统计信息，那这些呢，可能就只有几MB，或者几十MB级别的数据，他的价值是非常大的。

比如说，商家呢愿意去付费去购买这样的数据，从优化自己的广告投放的策略，所以说，识别各种不同数据它的成本以及对应的价值呢，能更好的指导你去做数据治理。 

## 八.数据共享

是展开数据共享的交换，从而实现内外部价值的一系列活动。

比如说你企业构建好了数据仓库，需要提供给算法团队，做模型的训练，或者说不通 BU之间，他们需要 share 数据进行一些合作的共赢，或者说你的数据通过合法的方式对外发布，从而实现你价值的兑现等等之类的，`它核心都是要建立一套数据的标准规范，以及相应的共享制度，然后通过数据运营的方式不断去改进。`



## 最后

我们来看一张图：

<img src="1.assets/image-20220524225448128.png" alt="image-20220524225448128" style="zoom:50%;" />





这里罗列了数据资产管理的8个方面，我们可以看到：

- 标准和模型 都是以 文档化的方式加以罗列和引用就可以了；
- 元数据呢，承上启下，它给了主数据强有力的支撑；
- 数据质量呢，会根据数据标准和模型定义去核查主数据的质量，我们说的数据资产呢，主要就是元数据和主数据的部分；
- 并且会围绕着数据价值和数据共享的一系列的活动来展开；
- 数据安全呢，会伴随着数据治理整个的生命周期来展开。

## 数据质量管理手段

介绍数据质量在落地过程中的一些实践，以及最终如何促进质量和效率的双重提升。分四个方面展开，分别是：

手段、质量标准、流程、持续改进。

### 手段

比如说数据的完整性，究竟该怎样去统计他。

正确性究竟该怎样去核查他的正确；

一致性又该怎样去评估。

那我们总结了三种抽象的办法来完成这个事情，分别是：抽样、统计和规则。

- 抽样就是对数据集合进行采样，来做质检。比如说你有n条数据集的记录，那你可以从原始数据中随机选择根号n条记录，并且找到他最原始，最真实的数据进行比对，从而保证数据的正确性。最原始的数据，可能在你的erp系统中、crm系统中或者说你的数据库中。
- 统计，总共有多少张表，非空表的比例如何，有多少列，非空列的比例如何，可以把这些数据绘制成图表，把握和感知整体数据的分布，从而做质量的核查。那在实际的大数据治理项目中，按照取值统计来做质检，是非常使用和非常有效的，它让你更好的感知数据集的分布，并发现一些长尾的异常数据。
- 规则，比如数据数据规范性这一方面，那gender 性别，它类型是否真的为 int，它的值域是否在"0129"四个取值中。比如说，在数据一致性方面，那你下单的记录，是否有完整的网站访问记录；或者说数据的时效性方面，下单时间是否早于你的付款时间 等等这些指标，都可以具象化成特定的规则，来程序化的执行，从而节省你人的时间。

### 质量标准

第二个方面，是数据质量标准的定义，没有标准就无法量化，那也无法谈改进，上下游之间就会有扯不完的皮，所以数据质量标准的定义，是最难的部分，但是又非常必要。

那比如说，我们举一条数据完整性的一个数据质量标准的例子：比如说我们认为不能存在空的表，且不能有超过5%的列为空，排除那么几个重要的列是必须不能为空的，那满足这个条件呢，我们才会认为数据通过了数据完整性的咱们一个校验。

那当然其它的几个方面，比如说，数据的一致性、完整性、规范性 都有非常多的数据质量标准可以去细化来定义。并且定好的数据质量标准，需要数据衔接的上下游都认掉，这才是一个可以落地的质量标准。

当然，我们无法一次性的去定义出一个非常合理的标准，所以说数据质量标准的定义，是一个需要持续迭代，反复确认的这样一个过程。

### 流程

我们需要制定好，围绕数据质量管理的流程体系，比如说在整个数据生成链路中的多个关键环节，我们要做数据质量的把控，那在这些关键的数据节点的话，那一般是QA质量控制这样的角色会介入，产出一份质量核查的报告作为一个核心的交付物。

如果说报告不满足我们之前提到的数据质量的标准，那就会打回，让上游的ETL来修复，或者说非处无法修复的原因。

那当存在一些质量风险的时候，项目经理需要及时的介入，不管是把控项目的进度，内外部的沟通还是控制用户对于质量的预期，都可以介入，并加以控制。

### 持续改进

在数据生产领域的话，效率问题本质上是一个质量问题，那成本-效率-质量 永远是互相平衡的铁三角，就类似于（分布式）技术领域中的CAP原理。

那软件工程领域对于提升软件质量的办法，是通过CI/CD 的方式，自动化软件质量的验证，并通过UT和API test，来快速的暴露问题，从而提升软件的质量。

那映射到数据生成领域的话，核心就两点，`第一点就是"数据质检的自动化"，第二点是"数据质检规则的持续积累"`，**那快速的发现指出问题本身，就已经是高效率的体现。而持续的质检规则的积累，就可以把人的工作不断变成机器的工作，从而提升人的效能**，那狠抓这两个关键点，就能把降低成本，提升质量，提升效率的平衡点推上一个新的台阶。那这一点呢，在我过去工作几年的过程中，是一个非常深刻的体会。



